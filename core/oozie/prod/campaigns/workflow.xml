<workflow-app xmlns="uri:oozie:workflow:0.5" name="dap-campaigns-wf">

    <global>
        <job-tracker>${jobTracker}</job-tracker>
        <name-node>${nameNode}</name-node>
        <configuration>
            <property>
                <name>mapreduce.job.queuename</name>
                <value>${queueName}</value>
            </property>
        </configuration>
    </global>

    <start to='ItrCmrFork' />

    <fork name="ItrCmrFork">
        <path start="basicITR" />
        <path start="clickstreamYesterdaySession" />
        <path start="pricingSKUData" />
    </fork>

    <action name="basicITR">
        <shell xmlns="uri:oozie:shell-action:0.3">
            <exec>run.pl</exec>
            <argument>-t</argument>
            <argument>${jobEnv}</argument>
            <argument>-c</argument>
            <argument>basicITR</argument>
            <env-var>YARN_CONF_DIR=/etc/hadoop/conf</env-var>
            <env-var>HADOOP_USER_NAME=${wf:user()}</env-var>
            <file>${scriptHome}/run.pl#run.pl</file>
            <capture-output/>
        </shell>
        <ok to="recommendations"/>
        <error to="fail"/>
    </action>

    <action name="recommendations">
        <shell xmlns="uri:oozie:shell-action:0.3">
            <exec>run.pl</exec>
            <argument>-t</argument>
            <argument>${jobEnv}</argument>
            <argument>-c</argument>
            <argument>recommendations</argument>
            <env-var>YARN_CONF_DIR=/etc/hadoop/conf</env-var>
            <env-var>HADOOP_USER_NAME=${wf:user()}</env-var>
            <file>${scriptHome}/run.pl#run.pl</file>
            <capture-output/>
        </shell>
        <ok to="ItrCmrJoin"/>
        <error to="fail"/>
    </action>

    <action name="clickstreamYesterdaySession">
        <shell xmlns="uri:oozie:shell-action:0.3">
            <exec>run.pl</exec>
            <argument>-t</argument>
            <argument>${jobEnv}</argument>
            <argument>-c</argument>
            <argument>clickstreamYesterdaySession</argument>
            <env-var>YARN_CONF_DIR=/etc/hadoop/conf</env-var>
            <env-var>HADOOP_USER_NAME=${wf:user()}</env-var>
            <file>${scriptHome}/run.pl#run.pl</file>
            <capture-output/>
        </shell>
        <ok to="CmrClickstreamFork"/>
        <error to="fail"/>
    </action>

    <fork name="CmrClickstreamFork">
        <path start="clickstreamSurf3Variable" />
        <path start="customerDeviceMapping" />
    </fork>

    <action name="clickstreamSurf3Variable">
        <shell xmlns="uri:oozie:shell-action:0.3">
            <exec>run.pl</exec>
            <argument>-t</argument>
            <argument>${jobEnv}</argument>
            <argument>-c</argument>
            <argument>clickstreamSurf3Variable</argument>
            <env-var>YARN_CONF_DIR=/etc/hadoop/conf</env-var>
            <env-var>HADOOP_USER_NAME=${wf:user()}</env-var>
            <file>${scriptHome}/run.pl#run.pl</file>
            <capture-output/>
        </shell>
        <ok to="CmrClickstreamJoin"/>
        <error to="fail"/>
    </action>

    <action name="customerDeviceMapping">
        <shell xmlns="uri:oozie:shell-action:0.3">
            <exec>run.pl</exec>
            <argument>-t</argument>
            <argument>${jobEnv}</argument>
            <argument>-c</argument>
            <argument>customerDeviceMapping</argument>
            <env-var>YARN_CONF_DIR=/etc/hadoop/conf</env-var>
            <env-var>HADOOP_USER_NAME=${wf:user()}</env-var>
            <file>${scriptHome}/run.pl#run.pl</file>
            <capture-output/>
        </shell>
        <ok to="CmrClickstreamJoin"/>
        <error to="fail"/>
    </action>

    <join name="CmrClickstreamJoin" to="ItrCmrJoin"/>

    <action name="pricingSKUData">
        <shell xmlns="uri:oozie:shell-action:0.3">
            <exec>run.pl</exec>
            <argument>-t</argument>
            <argument>${jobEnv}</argument>
            <argument>-c</argument>
            <argument>pricingSKUData</argument>
            <env-var>YARN_CONF_DIR=/etc/hadoop/conf</env-var>
            <env-var>HADOOP_USER_NAME=${wf:user()}</env-var>
            <file>${scriptHome}/run.pl#run.pl</file>
            <capture-output/>
        </shell>
        <ok to="pricingSKUDataFtpUpload"/>
        <error to="fail"/>
    </action>

    <action name="pricingSKUDataFtpUpload">
        <shell xmlns="uri:oozie:shell-action:0.3">
            <exec>ftp_upload.pl</exec>
            <argument>-t</argument>
            <argument>${jobEnv}</argument>
            <argument>-c</argument>
            <argument>pricing_sku_data</argument>
            <env-var>YARN_CONF_DIR=/etc/hadoop/conf</env-var>
            <env-var>HADOOP_USER_NAME=${wf:user()}</env-var>
            <file>${scriptHome}/ftp_upload.pl#ftp_upload.pl</file>
            <capture-output/>
        </shell>
        <ok to="ItrCmrJoin"/>
        <error to="fail"/>
    </action>

    <join name="ItrCmrJoin" to="dcfFeedSurfCampaignStart"/>

    <fork name="dcfFeedSurfCampaignStart">
        <path start="surfCampaign" />
        <path start="dcfFeedGenerate" />
    </fork>

    <action name="surfCampaign">
        <shell xmlns="uri:oozie:shell-action:0.3">
            <exec>run.pl</exec>
            <argument>-t</argument>
            <argument>${jobEnv}</argument>
            <argument>-c</argument>
            <argument>surfCampaign</argument>
            <env-var>YARN_CONF_DIR=/etc/hadoop/conf</env-var>
            <env-var>HADOOP_USER_NAME=${wf:user()}</env-var>
            <file>${scriptHome}/run.pl#run.pl</file>
            <capture-output/>
        </shell>
        <ok to="dcfFeedSurfCampaignJoin"/>
        <error to="fail"/>
    </action>

    <action name="dcfFeedGenerate">
        <shell xmlns="uri:oozie:shell-action:0.3">
            <exec>run.pl</exec>
            <argument>-t</argument>
            <argument>${jobEnv}</argument>
            <argument>-c</argument>
            <argument>dcfFeedGenerate</argument>
            <env-var>YARN_CONF_DIR=/etc/hadoop/conf</env-var>
            <env-var>HADOOP_USER_NAME=${wf:user()}</env-var>
            <file>${scriptHome}/run.pl#run.pl</file>
            <capture-output/>
        </shell>
        <ok to="dcfFeedFtpUpload"/>
        <error to="fail"/>
    </action>

    <action name="dcfFeedFtpUpload">
        <shell xmlns="uri:oozie:shell-action:0.3">
            <exec>ftp_upload.pl</exec>
            <argument>-t</argument>
            <argument>${jobEnv}</argument>
            <argument>-c</argument>
            <argument>dcf_feed</argument>
            <env-var>YARN_CONF_DIR=/etc/hadoop/conf</env-var>
            <env-var>HADOOP_USER_NAME=${wf:user()}</env-var>
            <file>${scriptHome}/ftp_upload.pl#ftp_upload.pl</file>
            <capture-output/>
        </shell>
        <ok to="dcfFeedSurfCampaignJoin"/>
        <error to="fail"/>
    </action>

    <join name="dcfFeedSurfCampaignJoin" to="campaignsStart"/>

    <fork name="campaignsStart">
        <path start="retargetCampaign" />
        <path start="invalidCampaign" />
        <path start="abandonedCartCampaign" />
        <path start="wishlistCampaign" />
    </fork>

    <action name="retargetCampaign">
        <shell xmlns="uri:oozie:shell-action:0.3">
            <exec>run.pl</exec>
            <argument>-t</argument>
            <argument>${jobEnv}</argument>
            <argument>-c</argument>
            <argument>retargetCampaign</argument>
            <env-var>YARN_CONF_DIR=/etc/hadoop/conf</env-var>
            <env-var>HADOOP_USER_NAME=${wf:user()}</env-var>
            <file>${scriptHome}/run.pl#run.pl</file>
            <capture-output/>
        </shell>
        <ok to="campaignsJoin"/>
        <error to="fail"/>
    </action>

    <action name="invalidCampaign">
        <shell xmlns="uri:oozie:shell-action:0.3">
            <exec>run.pl</exec>
            <argument>-t</argument>
            <argument>${jobEnv}</argument>
            <argument>-c</argument>
            <argument>invalidCampaign</argument>
            <env-var>YARN_CONF_DIR=/etc/hadoop/conf</env-var>
            <env-var>HADOOP_USER_NAME=${wf:user()}</env-var>
            <file>${scriptHome}/run.pl#run.pl</file>
            <capture-output/>
        </shell>
        <ok to="campaignsJoin"/>
        <error to="fail"/>
    </action>
    <action name="abandonedCartCampaign">
        <shell xmlns="uri:oozie:shell-action:0.3">
            <exec>run.pl</exec>
            <argument>-t</argument>
            <argument>${jobEnv}</argument>
            <argument>-c</argument>
            <argument>abandonedCartCampaign</argument>
            <env-var>YARN_CONF_DIR=/etc/hadoop/conf</env-var>
            <env-var>HADOOP_USER_NAME=${wf:user()}</env-var>
            <file>${scriptHome}/run.pl#run.pl</file>
            <capture-output/>
        </shell>
        <ok to="campaignsJoin"/>
        <error to="fail"/>
    </action>
    <action name="wishlistCampaign">
        <shell xmlns="uri:oozie:shell-action:0.3">
            <exec>run.pl</exec>
            <argument>-t</argument>
            <argument>${jobEnv}</argument>
            <argument>-c</argument>
            <argument>wishlistCampaign</argument>
            <env-var>YARN_CONF_DIR=/etc/hadoop/conf</env-var>
            <env-var>HADOOP_USER_NAME=${wf:user()}</env-var>
            <file>${scriptHome}/run.pl#run.pl</file>
            <capture-output/>
        </shell>
        <ok to="campaignsJoin"/>
        <error to="fail"/>
    </action>

    <join name="campaignsJoin" to="pushCampaignMerge"/>

    <action name="pushCampaignMerge">
        <shell xmlns="uri:oozie:shell-action:0.3">
            <exec>run.pl</exec>
            <argument>-t</argument>
            <argument>${jobEnv}</argument>
            <argument>-c</argument>
            <argument>pushCampaignMerge</argument>
            <env-var>YARN_CONF_DIR=/etc/hadoop/conf</env-var>
            <env-var>HADOOP_USER_NAME=${wf:user()}</env-var>
            <file>${scriptHome}/run.pl#run.pl</file>
            <capture-output/>
        </shell>
        <ok to="pushCampaignFtpUpload"/>
        <error to="fail"/>
    </action>

    <action name="pushCampaignFtpUpload">
        <shell xmlns="uri:oozie:shell-action:0.3">
            <exec>ftp_upload.pl</exec>
            <argument>-t</argument>
            <argument>${jobEnv}</argument>
            <argument>-c</argument>
            <argument>campaigns</argument>
            <env-var>YARN_CONF_DIR=/etc/hadoop/conf</env-var>
            <env-var>HADOOP_USER_NAME=${wf:user()}</env-var>
            <file>${scriptHome}/ftp_upload.pl#ftp_upload.pl</file>
            <capture-output/>
        </shell>
        <ok to="mobilePushCampaignQuality"/>
        <error to="fail"/>
    </action>

    <action name="mobilePushCampaignQuality">
        <shell xmlns="uri:oozie:shell-action:0.3">
            <exec>run.pl</exec>
            <argument>-t</argument>
            <argument>${jobEnv}</argument>
            <argument>-c</argument>
            <argument>mobilePushCampaignQuality</argument>
            <env-var>YARN_CONF_DIR=/etc/hadoop/conf</env-var>
            <env-var>HADOOP_USER_NAME=${wf:user()}</env-var>
            <file>${scriptHome}/run.pl#run.pl</file>
            <capture-output/>
        </shell>
        <ok to="end"/>
        <error to="fail"/>
    </action>

    <kill name="fail">
        <message>Workflow failed, error message[${wf:errorMessage(wf:lastErrorNode())}]</message>
    </kill>

    <end name="end" />

</workflow-app>