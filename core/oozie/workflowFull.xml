<workflow-app xmlns="uri:oozie:workflow:0.5" name="dap-full-wf">
    <global>
        <job-tracker>${jobTracker}</job-tracker>
        <name-node>${nameNode}</name-node>
        <configuration>
            <property>
                <name>mapred.job.queue.name</name>
                <value>${queueName}</value>
            </property>
        </configuration>
    </global>

    <start to='acquisition' />

    <fork name="acquisition">
        <path start="bobAcqFull1" />
        <path start="bobAcqFull2" />
        <path start="erpAcqIncr" />
    </fork>

    <action name="bobAcqFull1">
        <shell xmlns="uri:oozie:shell-action:0.2">
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <configuration>
                <property>
                    <name>mapred.job.queue.name</name>
                    <value>${queueName}</value>
                </property>
            </configuration>
            <exec>run.pl</exec>
            <argument>-t</argument>
            <argument>${jobEnv}</argument>
            <argument>-c</argument>
            <argument>bobAcqFull1</argument>
            <env-var>YARN_CONF_DIR=/etc/hadoop/conf</env-var>
            <env-var>HADOOP_USER_NAME=${wf:user()}</env-var>
            <file>${scriptHome}/run.pl#run.pl</file>
            <capture-output/>
        </shell>
        <ok to="bobAcqIncr"/>
        <error to="fail"/>
    </action>

    <action name="bobAcqIncr">
        <shell xmlns="uri:oozie:shell-action:0.2">
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <configuration>
                <property>
                    <name>mapred.job.queue.name</name>
                    <value>${queueName}</value>
                </property>
            </configuration>
            <exec>run.pl</exec>
            <argument>-t</argument>
            <argument>${jobEnv}</argument>
            <argument>-c</argument>
            <argument>bobAcqIncr</argument>
            <env-var>YARN_CONF_DIR=/etc/hadoop/conf</env-var>
            <env-var>HADOOP_USER_NAME=${wf:user()}</env-var>
            <file>${scriptHome}/run.pl#run.pl</file>
            <capture-output/>
        </shell>
        <ok to="bobMergeFork"/>
        <error to="fail"/>
    </action>

    <fork name="bobMergeFork">
        <path start="bobMerge" />
        <path start="bobMergeMonthly" />
    </fork>

    <action name="bobMerge">
        <shell xmlns="uri:oozie:shell-action:0.2">
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <configuration>
                <property>
                    <name>mapred.job.queue.name</name>
                    <value>${queueName}</value>
                </property>
            </configuration>
            <exec>run.pl</exec>
            <argument>-t</argument>
            <argument>${jobEnv}</argument>
            <argument>-c</argument>
            <argument>bobMerge</argument>
            <env-var>YARN_CONF_DIR=/etc/hadoop/conf</env-var>
            <env-var>HADOOP_USER_NAME=${wf:user()}</env-var>
            <file>${scriptHome}/run.pl#run.pl</file>
            <capture-output/>
        </shell>
        <ok to="bobMergeJoin"/>
        <error to="fail"/>
    </action>

    <action name="bobMergeMonthly">
        <shell xmlns="uri:oozie:shell-action:0.2">
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <configuration>
                <property>
                    <name>mapred.job.queue.name</name>
                    <value>${queueName}</value>
                </property>
            </configuration>
            <exec>run.pl</exec>
            <argument>-t</argument>
            <argument>${jobEnv}</argument>
            <argument>-c</argument>
            <argument>bobMergeMonthly</argument>
            <env-var>YARN_CONF_DIR=/etc/hadoop/conf</env-var>
            <env-var>HADOOP_USER_NAME=${wf:user()}</env-var>
            <file>${scriptHome}/run.pl#run.pl</file>
            <capture-output/>
        </shell>
        <ok to="bobMergeJoin"/>
        <error to="fail"/>
    </action>

    <join name="bobMergeJoin" to="bobErpJoin"/>

    <action name="bobAcqFull2">
        <shell xmlns="uri:oozie:shell-action:0.2">
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <configuration>
                <property>
                    <name>mapred.job.queue.name</name>
                    <value>${queueName}</value>
                </property>
            </configuration>
            <exec>run.pl</exec>
            <argument>-t</argument>
            <argument>${jobEnv}</argument>
            <argument>-c</argument>
            <argument>bobAcqFull2</argument>
            <env-var>YARN_CONF_DIR=/etc/hadoop/conf</env-var>
            <env-var>HADOOP_USER_NAME=${wf:user()}</env-var>
            <file>${scriptHome}/run.pl#run.pl</file>
            <capture-output/>
        </shell>
        <ok to="bobErpJoin"/>
        <error to="fail"/>
    </action>

    <action name="erpAcqIncr">
        <shell xmlns="uri:oozie:shell-action:0.2">
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <configuration>
                <property>
                    <name>mapred.job.queue.name</name>
                    <value>${queueName}</value>
                </property>
            </configuration>
            <exec>run.pl</exec>
            <argument>-t</argument>
            <argument>${jobEnv}</argument>
            <argument>-c</argument>
            <argument>erpAcqIncr</argument>
            <env-var>YARN_CONF_DIR=/etc/hadoop/conf</env-var>
            <env-var>HADOOP_USER_NAME=${wf:user()}</env-var>
            <file>${scriptHome}/run.pl#run.pl</file>
            <capture-output/>
        </shell>
        <ok to="erpMerge"/>
        <error to="fail"/>
    </action>

    <action name="erpMerge">
        <shell xmlns="uri:oozie:shell-action:0.2">
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <configuration>
                <property>
                    <name>mapred.job.queue.name</name>
                    <value>${queueName}</value>
                </property>
            </configuration>
            <exec>run.pl</exec>
            <argument>-t</argument>
            <argument>${jobEnv}</argument>
            <argument>-c</argument>
            <argument>erpMerge</argument>
            <env-var>YARN_CONF_DIR=/etc/hadoop/conf</env-var>
            <env-var>HADOOP_USER_NAME=${wf:user()}</env-var>
            <file>${scriptHome}/run.pl#run.pl</file>
            <capture-output/>
        </shell>
        <ok to="bobErpJoin"/>
        <error to="fail"/>
    </action>

    <join name="bobErpJoin" to="basicItr"/>

    <action name="basicItr">
        <shell xmlns="uri:oozie:shell-action:0.2">
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <configuration>
                <property>
                    <name>mapred.job.queue.name</name>
                    <value>${queueName}</value>
                </property>
            </configuration>
            <exec>run.pl</exec>
            <argument>-t</argument>
            <argument>${jobEnv}</argument>
            <argument>-c</argument>
            <argument>basicItr</argument>
            <env-var>YARN_CONF_DIR=/etc/hadoop/conf</env-var>
            <env-var>HADOOP_USER_NAME=${wf:user()}</env-var>
            <file>${scriptHome}/run.pl#run.pl</file>
            <capture-output/>
        </shell>
        <ok to="pushCampaignStart"/>
        <error to="fail"/>
    </action>

    <fork name="pushCampaignStart">
        <path start="pushRetargetCampaign" />
        <path start="pushInvalidCampaign" />
        <path start="pushAbandonedCartCampaign" />
        <path start="pushWishlistCampaign" />
        <path start="clickstreamDesktop" />
    </fork>

    <action name="pushRetargetCampaign">
        <shell xmlns="uri:oozie:shell-action:0.2">
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <configuration>
                <property>
                    <name>mapred.job.queue.name</name>
                    <value>${queueName}</value>
                </property>
            </configuration>
            <exec>run.pl</exec>
            <argument>-t</argument>
            <argument>${jobEnv}</argument>
            <argument>-c</argument>
            <argument>pushRetargetCampaign</argument>
            <env-var>YARN_CONF_DIR=/etc/hadoop/conf</env-var>
            <env-var>HADOOP_USER_NAME=${wf:user()}</env-var>
            <file>${scriptHome}/run.pl#run.pl</file>
            <capture-output/>
        </shell>
        <ok to="pushCampaignMergeJoin"/>
        <error to="fail"/>
    </action>

    <action name="pushInvalidCampaign">
        <shell xmlns="uri:oozie:shell-action:0.2">
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <configuration>
                <property>
                    <name>mapred.job.queue.name</name>
                    <value>${queueName}</value>
                </property>
            </configuration>
            <exec>run.pl</exec>
            <argument>-t</argument>
            <argument>${jobEnv}</argument>
            <argument>-c</argument>
            <argument>pushInvalidCampaign</argument>
            <env-var>YARN_CONF_DIR=/etc/hadoop/conf</env-var>
            <env-var>HADOOP_USER_NAME=${wf:user()}</env-var>
            <file>${scriptHome}/run.pl#run.pl</file>
            <capture-output/>
        </shell>
        <ok to="pushCampaignMergeJoin"/>
        <error to="fail"/>
    </action>
    <action name="pushAbandonedCartCampaign">
        <shell xmlns="uri:oozie:shell-action:0.2">
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <configuration>
                <property>
                    <name>mapred.job.queue.name</name>
                    <value>${queueName}</value>
                </property>
            </configuration>
            <exec>run.pl</exec>
            <argument>-t</argument>
            <argument>${jobEnv}</argument>
            <argument>-c</argument>
            <argument>pushAbandonedCartCampaign</argument>
            <env-var>YARN_CONF_DIR=/etc/hadoop/conf</env-var>
            <env-var>HADOOP_USER_NAME=${wf:user()}</env-var>
            <file>${scriptHome}/run.pl#run.pl</file>
            <capture-output/>
        </shell>
        <ok to="pushCampaignMergeJoin"/>
        <error to="fail"/>
    </action>
    <action name="pushWishlistCampaign">
        <shell xmlns="uri:oozie:shell-action:0.2">
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <configuration>
                <property>
                    <name>mapred.job.queue.name</name>
                    <value>${queueName}</value>
                </property>
            </configuration>
            <exec>run.pl</exec>
            <argument>-t</argument>
            <argument>${jobEnv}</argument>
            <argument>-c</argument>
            <argument>pushWishlistCampaign</argument>
            <env-var>YARN_CONF_DIR=/etc/hadoop/conf</env-var>
            <env-var>HADOOP_USER_NAME=${wf:user()}</env-var>
            <file>${scriptHome}/run.pl#run.pl</file>
            <capture-output/>
        </shell>
        <ok to="pushCampaignMergeJoin"/>
        <error to="fail"/>
    </action>

    <action name="clickstreamDesktop">
        <shell xmlns="uri:oozie:shell-action:0.2">
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <configuration>
                <property>
                    <name>mapred.job.queue.name</name>
                    <value>${queueName}</value>
                </property>
            </configuration>
            <exec>start-mr.sh</exec>
            <argument>${scriptHome}/webClickstream_pipeline/desktop.properties</argument>
            <argument>1</argument>
            <argument>${jobEnv}</argument>
            <env-var>YARN_CONF_DIR=/etc/hadoop/conf</env-var>
            <env-var>HADOOP_USER_NAME=${wf:user()}</env-var>
            <file>${scriptHome}/webClickstream_pipeline/start-mr.sh#start-mr.sh</file>
            <capture-output/>
        </shell>
        <ok to="clickstreamArtemis"/>
        <error to="fail"/>
    </action>
    <action name="clickstreamArtemis">
        <shell xmlns="uri:oozie:shell-action:0.2">
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <configuration>
                <property>
                    <name>mapred.job.queue.name</name>
                    <value>${queueName}</value>
                </property>
            </configuration>
            <exec>start-mr.sh</exec>
            <argument>${scriptHome}/artemisClickstream_pipeline/artemis.properties</argument>
            <argument>1</argument>
            <argument>${jobEnv}</argument>
            <env-var>YARN_CONF_DIR=/etc/hadoop/conf</env-var>
            <env-var>HADOOP_USER_NAME=${wf:user()}</env-var>
            <file>${scriptHome}/artemisClickstream_pipeline/start-mr.sh#start-mr.sh</file>
            <capture-output/>
        </shell>
        <ok to="clickstreamApps"/>
        <error to="fail"/>
    </action>
    <action name="clickstreamApps">
        <shell xmlns="uri:oozie:shell-action:0.2">
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <configuration>
                <property>
                    <name>mapred.job.queue.name</name>
                    <value>${queueName}</value>
                </property>
            </configuration>
            <exec>start-mr.sh</exec>
            <argument>${scriptHome}/appClickstream_pipeline/apps.properties</argument>
            <argument>1</argument>
            <argument>${jobEnv}</argument>
            <env-var>YARN_CONF_DIR=/etc/hadoop/conf</env-var>
            <env-var>HADOOP_USER_NAME=${wf:user()}</env-var>
            <file>${scriptHome}/appClickstream_pipeline/start-mr.sh#start-mr.sh</file>
            <capture-output/>
        </shell>
        <ok to="clickstreamYesterdaySession"/>
        <error to="fail"/>
    </action>

    <action name="clickstreamYesterdaySession">
        <shell xmlns="uri:oozie:shell-action:0.2">
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <configuration>
                <property>
                    <name>mapred.job.queue.name</name>
                    <value>${queueName}</value>
                </property>
            </configuration>
            <exec>run.pl</exec>
            <argument>-t</argument>
            <argument>${jobEnv}</argument>
            <argument>-c</argument>
            <argument>clickstreamYesterdaySession</argument>
            <env-var>YARN_CONF_DIR=/etc/hadoop/conf</env-var>
            <env-var>HADOOP_USER_NAME=${wf:user()}</env-var>
            <file>${scriptHome}/run.pl#run.pl</file>
            <capture-output/>
        </shell>
        <ok to="clickstreamSurf3Variable"/>
        <error to="fail"/>
    </action>

    <action name="clickstreamSurf3Variable">
        <shell xmlns="uri:oozie:shell-action:0.2">
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <configuration>
                <property>
                    <name>mapred.job.queue.name</name>
                    <value>${queueName}</value>
                </property>
            </configuration>
            <exec>run.pl</exec>
            <argument>-t</argument>
            <argument>${jobEnv}</argument>
            <argument>-c</argument>
            <argument>clickstreamSurf3Variable</argument>
            <env-var>YARN_CONF_DIR=/etc/hadoop/conf</env-var>
            <env-var>HADOOP_USER_NAME=${wf:user()}</env-var>
            <file>${scriptHome}/run.pl#run.pl</file>
            <capture-output/>
        </shell>
        <ok to="deviceMapping"/>
        <error to="fail"/>
    </action>

    <action name="deviceMapping">
        <shell xmlns="uri:oozie:shell-action:0.2">
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <configuration>
                <property>
                    <name>mapred.job.queue.name</name>
                    <value>${queueName}</value>
                </property>
            </configuration>
            <exec>run.pl</exec>
            <argument>-t</argument>
            <argument>${jobEnv}</argument>
            <argument>-c</argument>
            <argument>deviceMapping</argument>
            <env-var>YARN_CONF_DIR=/etc/hadoop/conf</env-var>
            <env-var>HADOOP_USER_NAME=${wf:user()}</env-var>
            <file>${scriptHome}/run.pl#run.pl</file>
            <capture-output/>
        </shell>
        <ok to="pushSurfCampaign"/>
        <error to="fail"/>
    </action>

    <action name="pushSurfCampaign">
        <shell xmlns="uri:oozie:shell-action:0.2">
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <configuration>
                <property>
                    <name>mapred.job.queue.name</name>
                    <value>${queueName}</value>
                </property>
            </configuration>
            <exec>run.pl</exec>
            <argument>-t</argument>
            <argument>${jobEnv}</argument>
            <argument>-c</argument>
            <argument>pushSurfCampaign</argument>
            <env-var>YARN_CONF_DIR=/etc/hadoop/conf</env-var>
            <env-var>HADOOP_USER_NAME=${wf:user()}</env-var>
            <file>${scriptHome}/run.pl#run.pl</file>
            <capture-output/>
        </shell>
        <ok to="pushCampaignMergeJoin"/>
        <error to="fail"/>
    </action>

    <join name="pushCampaignMergeJoin" to="pushCamapignFork"/>

    <fork name="pushCamapignFork">
        <path start="pushCampaignMerge" />
        <path start="dcfFeedGenerate" />
        <path start="pricingSKUData" />
    </fork>

    <action name="pushCampaignMerge">
        <shell xmlns="uri:oozie:shell-action:0.2">
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <configuration>
                <property>
                    <name>mapred.job.queue.name</name>
                    <value>${queueName}</value>
                </property>
            </configuration>
            <exec>run.pl</exec>
            <argument>-t</argument>
            <argument>${jobEnv}</argument>
            <argument>-c</argument>
            <argument>pushCampaignMerge</argument>
            <env-var>YARN_CONF_DIR=/etc/hadoop/conf</env-var>
            <env-var>HADOOP_USER_NAME=${wf:user()}</env-var>
            <file>${scriptHome}/run.pl#run.pl</file>
            <capture-output/>
        </shell>
        <ok to="mobilePushCampaignQuality"/>
        <error to="fail"/>
    </action>
    <action name="mobilePushCampaignQuality">
        <shell xmlns="uri:oozie:shell-action:0.2">
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <configuration>
                <property>
                    <name>mapred.job.queue.name</name>
                    <value>${queueName}</value>
                </property>
            </configuration>
            <exec>run.pl</exec>
            <argument>-t</argument>
            <argument>${jobEnv}</argument>
            <argument>-c</argument>
            <argument>mobilePushCampaignQuality</argument>
            <env-var>YARN_CONF_DIR=/etc/hadoop/conf</env-var>
            <env-var>HADOOP_USER_NAME=${wf:user()}</env-var>
            <file>${scriptHome}/run.pl#run.pl</file>
            <capture-output/>
        </shell>
        <ok to="endJoin"/>
        <error to="fail"/>
    </action>

    <action name="dcfFeedGenerate">
        <shell xmlns="uri:oozie:shell-action:0.2">
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <configuration>
                <property>
                    <name>mapred.job.queue.name</name>
                    <value>${queueName}</value>
                </property>
            </configuration>
            <exec>run.pl</exec>
            <argument>-t</argument>
            <argument>${jobEnv}</argument>
            <argument>-c</argument>
            <argument>dcfFeedGenerate</argument>
            <env-var>YARN_CONF_DIR=/etc/hadoop/conf</env-var>
            <env-var>HADOOP_USER_NAME=${wf:user()}</env-var>
            <file>${scriptHome}/run.pl#run.pl</file>
            <capture-output/>
        </shell>
        <ok to="endJoin"/>
        <error to="fail"/>
    </action>

    <action name="pricingSKUData">
        <shell xmlns="uri:oozie:shell-action:0.2">
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <configuration>
                <property>
                    <name>mapred.job.queue.name</name>
                    <value>${queueName}</value>
                </property>
            </configuration>
            <exec>run.pl</exec>
            <argument>-t</argument>
            <argument>${jobEnv}</argument>
            <argument>-c</argument>
            <argument>pricingSKUData</argument>
            <env-var>YARN_CONF_DIR=/etc/hadoop/conf</env-var>
            <env-var>HADOOP_USER_NAME=${wf:user()}</env-var>
            <file>${scriptHome}/run.pl#run.pl</file>
            <capture-output/>
        </shell>
        <ok to="endJoin"/>
        <error to="fail"/>
    </action>

    <join name="endJoin" to="end"/>

    <kill name="fail">
        <message>Workflow failed, error message[${wf:errorMessage(wf:lastErrorNode())}]</message>
    </kill>

    <end name="end" />

</workflow-app>